/**
 * ONNX Runtime ç«¯åˆ°ç«¯æ¨ç†éªŒè¯è„šæœ¬
 * éªŒè¯ onnxruntime-node èƒ½å¦åŠ è½½å ä½ ONNX æ¨¡å‹å¹¶æ‰§è¡Œæ¨ç†
 */
import { createRequire } from 'module';
import { resolve, dirname } from 'path';
import { fileURLToPath } from 'url';

const require = createRequire(import.meta.url);
const __dirname = dirname(fileURLToPath(import.meta.url));

async function verify() {
  console.log('=== ONNX Runtime ç«¯åˆ°ç«¯æ¨ç†éªŒè¯ ===\n');

  // 1. åŠ è½½ onnxruntime-node
  let ort;
  try {
    ort = require('onnxruntime-node');
    console.log('âœ… onnxruntime-node åŠ è½½æˆåŠŸ');
    console.log('   å¯¼å‡º API:', Object.keys(ort).join(', '));
  } catch (e) {
    console.error('âŒ onnxruntime-node åŠ è½½å¤±è´¥:', e.message);
    process.exit(1);
  }

  // 2. åŠ è½½ ONNX æ¨¡å‹
  const modelPath = resolve(__dirname, '../server/platform/evolution/models/world-model-lstm.onnx');
  console.log(`\nğŸ“¦ æ¨¡å‹è·¯å¾„: ${modelPath}`);

  let session;
  try {
    session = await ort.InferenceSession.create(modelPath, {
      executionProviders: ['cpu'],
    });
    console.log('âœ… ONNX æ¨¡å‹åŠ è½½æˆåŠŸ');
    console.log('   è¾“å…¥èŠ‚ç‚¹:', session.inputNames);
    console.log('   è¾“å‡ºèŠ‚ç‚¹:', session.outputNames);
  } catch (e) {
    console.error('âŒ ONNX æ¨¡å‹åŠ è½½å¤±è´¥:', e.message);
    process.exit(1);
  }

  // 3. æ„é€ è¾“å…¥å¼ é‡å¹¶æ‰§è¡Œæ¨ç†
  try {
    // æ ¹æ®æ¨¡å‹è¾“å…¥å½¢çŠ¶æ„é€ æ•°æ®
    // å ä½æ¨¡å‹: input shape [1, 60, 32] (batch=1, seq_len=60, feature_dim=32)
    const seqLen = 60;
    const featureDim = 32;
    const inputData = new Float32Array(1 * seqLen * featureDim);
    for (let i = 0; i < inputData.length; i++) {
      inputData[i] = Math.random() * 2 - 1; // [-1, 1] éšæœºå€¼
    }

    const inputTensor = new ort.Tensor('float32', inputData, [1, seqLen, featureDim]);
    console.log(`\nğŸ”¢ è¾“å…¥å¼ é‡: shape=[1, ${seqLen}, ${featureDim}], dtype=float32`);

    const feeds = {};
    feeds[session.inputNames[0]] = inputTensor;

    const startTime = Date.now();
    const results = await session.run(feeds);
    const latencyMs = Date.now() - startTime;

    const outputName = session.outputNames[0];
    const outputTensor = results[outputName];
    console.log(`âœ… æ¨ç†æˆåŠŸ (${latencyMs}ms)`);
    console.log(`   è¾“å‡ºèŠ‚ç‚¹: ${outputName}`);
    console.log(`   è¾“å‡ºå½¢çŠ¶: [${outputTensor.dims}]`);
    console.log(`   è¾“å‡ºç±»å‹: ${outputTensor.type}`);
    console.log(`   è¾“å‡ºæ ·æœ¬ (å‰ 8 å€¼): [${Array.from(outputTensor.data).slice(0, 8).map(v => v.toFixed(6)).join(', ')}]`);

    // 4. æ€§èƒ½åŸºå‡†æµ‹è¯• (10 æ¬¡æ¨ç†)
    console.log('\nâ±ï¸  æ€§èƒ½åŸºå‡† (10 æ¬¡æ¨ç†):');
    const latencies = [];
    for (let i = 0; i < 10; i++) {
      const t0 = Date.now();
      await session.run(feeds);
      latencies.push(Date.now() - t0);
    }
    const avg = latencies.reduce((a, b) => a + b, 0) / latencies.length;
    const min = Math.min(...latencies);
    const max = Math.max(...latencies);
    console.log(`   å¹³å‡: ${avg.toFixed(1)}ms, æœ€å°: ${min}ms, æœ€å¤§: ${max}ms`);

    console.log('\nâœ…âœ…âœ… ONNX Runtime ç«¯åˆ°ç«¯éªŒè¯å…¨éƒ¨é€šè¿‡ âœ…âœ…âœ…');
  } catch (e) {
    console.error('âŒ æ¨ç†æ‰§è¡Œå¤±è´¥:', e.message);
    console.error(e.stack);
    process.exit(1);
  }
}

verify().catch(e => {
  console.error('éªŒè¯è„šæœ¬å¼‚å¸¸:', e);
  process.exit(1);
});
